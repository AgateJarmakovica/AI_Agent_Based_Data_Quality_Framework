"""
Streamlit Web UI for healthdq-ai with Human-in-the-Loop
Author: Agate JarmakoviÄa

InteraktÄ«vs interfeiss ar pilnu HITL workflow:
1. Datu augÅ¡upielÄde
2. SÄkotnÄ“jais novÄ“rtÄ“jums (PIRMS izmaiÅ†Äm)
3. CilvÄ“ka apstiprinÄÅ¡ana
4. Datu transformÄcija
5. RezultÄtu pÄrskats
"""

import streamlit as st
import pandas as pd
import asyncio
from pathlib import Path

# Check for optional ML dependencies
ML_FEATURES_AVAILABLE = True
MISSING_DEPENDENCIES = []

try:
    import langchain
except ImportError:
    ML_FEATURES_AVAILABLE = False
    MISSING_DEPENDENCIES.append("langchain")

try:
    import chromadb
except ImportError:
    ML_FEATURES_AVAILABLE = False
    MISSING_DEPENDENCIES.append("chromadb")

try:
    import torch
except ImportError:
    # Torch is optional, warn but don't disable features
    MISSING_DEPENDENCIES.append("torch")

# Configure page
st.set_page_config(
    page_title="healthdq-ai - Data Quality Framework",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Initialize session state
if "data" not in st.session_state:
    st.session_state.data = None
if "quality_results" not in st.session_state:
    st.session_state.quality_results = None
if "review_session" not in st.session_state:
    st.session_state.review_session = None
if "approval_request" not in st.session_state:
    st.session_state.approval_request = None
if "improved_data" not in st.session_state:
    st.session_state.improved_data = None
if "workflow_stage" not in st.session_state:
    st.session_state.workflow_stage = "upload"


def _simulate_analysis(data: pd.DataFrame, dimensions: list) -> dict:
    """
    Simulate quality analysis when ML features are not available.
    Provides basic rule-based analysis without LLM/vector DB.
    """
    import numpy as np

    results = {
        "overall_score": 0.0,
        "dimension_results": {},
        "improvement_plan": {"actions": []},
        "metadata": {
            "total_issues": 0,
            "confidence": 0.7,  # Lower confidence for simulated results
            "mode": "simulated"
        }
    }

    total_score = 0

    # Analyze each dimension with basic rules
    for dimension in dimensions:
        dim_results = {
            "score": 0.0,
            "issues": [],
            "suggestions": []
        }

        if dimension == "completeness":
            # Check for missing values
            missing_count = data.isna().sum()
            missing_pct = (data.isna().sum() / len(data)) * 100

            for col in data.columns:
                if missing_count[col] > 0:
                    severity = "critical" if missing_pct[col] > 50 else "high" if missing_pct[col] > 20 else "medium"
                    dim_results["issues"].append({
                        "type": "missing_values",
                        "column": col,
                        "description": f"KolonnÄ '{col}' trÅ«kst {missing_count[col]} vÄ“rtÄ«bas ({missing_pct[col]:.1f}%)",
                        "severity": severity,
                        "count": int(missing_count[col])
                    })

                    results["improvement_plan"]["actions"].append({
                        "column": col,
                        "recommended_action": f"AizpildÄ«t trÅ«kstoÅ¡Äs vÄ“rtÄ«bas kolonnÄ '{col}'",
                        "severity": severity
                    })

            # Calculate score
            overall_missing_pct = (data.isna().sum().sum() / (len(data) * len(data.columns))) * 100
            dim_results["score"] = max(0, 1 - (overall_missing_pct / 100))

        elif dimension == "precision":
            # Check data types and format consistency
            for col in data.columns:
                if data[col].dtype == 'object':
                    # Check for inconsistent formats
                    unique_count = data[col].nunique()
                    if unique_count > len(data) * 0.5:
                        dim_results["issues"].append({
                            "type": "format_inconsistency",
                            "column": col,
                            "description": f"KolonnÄ '{col}' ir daudz unikÄlu vÄ“rtÄ«bu ({unique_count}), iespÄ“jams formÄta nekonsekvence",
                            "severity": "medium"
                        })

            # Simple score based on numeric vs object columns
            numeric_cols = len(data.select_dtypes(include=[np.number]).columns)
            total_cols = len(data.columns)
            dim_results["score"] = 0.7 + (numeric_cols / total_cols) * 0.3

        elif dimension == "reusability":
            # Basic FAIR principles check
            issues_count = 0

            # Check column names (should be descriptive)
            for col in data.columns:
                if len(col) < 2 or col.isdigit():
                    dim_results["issues"].append({
                        "type": "poor_naming",
                        "column": col,
                        "description": f"Kolonnai '{col}' ir nepietiekoÅ¡i aprakstoÅ¡s nosaukums",
                        "severity": "low"
                    })
                    issues_count += 1

            dim_results["score"] = max(0.5, 1 - (issues_count / len(data.columns)))

        total_score += dim_results["score"]
        results["dimension_results"][dimension] = dim_results
        results["metadata"]["total_issues"] += len(dim_results["issues"])

    # Calculate overall score
    results["overall_score"] = total_score / len(dimensions) if dimensions else 0.5

    return results


def main():
    """Main application."""

    # Show ML features warning if dependencies are missing
    if not ML_FEATURES_AVAILABLE:
        st.warning(
            f"âš ï¸ **Demo reÅ¾Ä«ms**: DaÅ¾i ML funkcionalitÄte nav pieejama. "
            f"TrÅ«kstoÅ¡ie paketes: {', '.join(MISSING_DEPENDENCIES)}. "
            f"Lai iespÄ“jotu pilnu funkcionalitÄti, instalÄ“jiet: `pip install -r requirements.txt`"
        )
    elif MISSING_DEPENDENCIES:
        st.info(
            f"â„¹ï¸ DaÅ¾i neobligÄtie komponenti nav instalÄ“ti: {', '.join(MISSING_DEPENDENCIES)}. "
            f"Pamata funkcionalitÄte ir pieejama."
        )

    # Sidebar
    with st.sidebar:
        st.title("ğŸ¥ healthdq-ai")
        st.markdown("**AI Agent-Based Data Quality Framework**")
        st.markdown("---")

        # Workflow stages
        st.subheader("ğŸ“‹ Workflow")

        stages = {
            "upload": "1ï¸âƒ£ AugÅ¡upielÄde",
            "assessment": "2ï¸âƒ£ NovÄ“rtÄ“jums",
            "review": "3ï¸âƒ£ PÄrskatÄ«Å¡ana",
            "approval": "4ï¸âƒ£ ApstiprinÄÅ¡ana",
            "transformation": "5ï¸âƒ£ TransformÄcija",
            "results": "6ï¸âƒ£ RezultÄti",
        }

        current_stage = st.session_state.workflow_stage

        for stage_id, stage_name in stages.items():
            if stage_id == current_stage:
                st.markdown(f"**â†’ {stage_name}** âœ“")
            else:
                st.markdown(f"   {stage_name}")

        st.markdown("---")

        # Settings
        with st.expander("âš™ï¸ IestatÄ«jumi"):
            st.session_state.auto_approve_threshold = st.slider(
                "Auto-approve slieksnis",
                0.0, 1.0, 0.95,
                help="AI automÄtiski apstiprina izmaiÅ†as ar Å¡o vai augstÄku pÄrliecÄ«bu"
            )

            st.session_state.require_all_approvals = st.checkbox(
                "PrasÄ«t katras izmaiÅ†as apstiprinÄÅ¡anu",
                value=False,
                help="Ja ieslÄ“gts, katrai izmaiÅ†ai jÄapstiprina atseviÅ¡Ä·i"
            )

        st.markdown("---")

        # About
        with st.expander("â„¹ï¸ Par"):
            st.markdown("""
            **healthdq-ai v2.0**

            Multi-agent data quality framework ar Human-in-the-Loop.

            - ğŸ¤– AI aÄ£enti
            - ğŸ”„ HITL validÄcija
            - ğŸ“Š FAIR principi
            - ğŸ§  Adaptive learning
            """)

    # Main content
    st.title("ğŸ¥ healthdq-ai: Data Quality Framework")

    # Display current stage
    if current_stage == "upload":
        show_upload_stage()
    elif current_stage == "assessment":
        show_assessment_stage()
    elif current_stage == "review":
        show_review_stage()
    elif current_stage == "approval":
        show_approval_stage()
    elif current_stage == "transformation":
        show_transformation_stage()
    elif current_stage == "results":
        show_results_stage()


def show_upload_stage():
    """Stage 1: Data upload."""
    st.header("1ï¸âƒ£ Datu AugÅ¡upielÄde")

    st.markdown("""
    AugÅ¡upielÄdÄ“jiet savu datu kopu analÄ«zei un kvalitÄtes uzlaboÅ¡anai.

    **AtbalstÄ«tie formÄti:** CSV, Excel, JSON, Parquet
    """)

    uploaded_file = st.file_uploader(
        "IzvÄ“lieties failu",
        type=["csv", "xlsx", "xls", "json", "parquet"],
    )

    if uploaded_file:
        try:
            # Load data based on file type
            file_extension = Path(uploaded_file.name).suffix.lower()

            with st.spinner("IelÄdÄ“ datus..."):
                if file_extension == ".csv":
                    data = pd.read_csv(uploaded_file)
                elif file_extension in [".xlsx", ".xls"]:
                    data = pd.read_excel(uploaded_file)
                elif file_extension == ".json":
                    data = pd.read_json(uploaded_file)
                elif file_extension == ".parquet":
                    data = pd.read_parquet(uploaded_file)
                else:
                    st.error(f"NeatbalstÄ«ts formÄts: {file_extension}")
                    return

            st.session_state.data = data
            st.success(f"âœ… Dati ielÄdÄ“ti: {data.shape[0]} rindas, {data.shape[1]} kolonnas")

            # Show data preview
            st.subheader("ğŸ“Š Datu PriekÅ¡skatÄ«jums")
            st.dataframe(data.head(10), use_container_width=True)

            # Show basic info
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Rindas", data.shape[0])
            with col2:
                st.metric("Kolonnas", data.shape[1])
            with col3:
                missing_pct = (data.isna().sum().sum() / (data.shape[0] * data.shape[1])) * 100
                st.metric("TrÅ«kstoÅ¡i %", f"{missing_pct:.1f}%")
            with col4:
                duplicates = data.duplicated().sum()
                st.metric("DublikÄti", duplicates)

            # Next button
            if st.button("â–¶ï¸ TurpinÄt uz NovÄ“rtÄ“jumu", type="primary", use_container_width=True):
                st.session_state.workflow_stage = "assessment"
                st.rerun()

        except Exception as e:
            st.error(f"âŒ KÄ¼Å«da ielÄdÄ“jot datus: {str(e)}")


def show_assessment_stage():
    """Stage 2: Initial assessment."""
    st.header("2ï¸âƒ£ Datu KvalitÄtes NovÄ“rtÄ“jums")

    if st.session_state.data is None:
        st.warning("âš ï¸ Nav ielÄdÄ“tu datu. Atgriezieties uz augÅ¡upielÄdes posmu.")
        return

    st.markdown("""
    **AI aÄ£enti analizÄ“ jÅ«su datus pÄ“c vairÄkÄm dimensijÄm:**
    - ğŸ¯ **Precision** - Format consistency, type validation
    - âœ… **Completeness** - Missing value detection
    - â™»ï¸ **Reusability** - FAIR principles compliance
    """)

    # Configuration
    with st.expander("âš™ï¸ AnalÄ«zes KonfigurÄcija"):
        dimensions = st.multiselect(
            "KvalitÄtes dimensijas",
            ["precision", "completeness", "reusability"],
            default=["precision", "completeness", "reusability"],
        )

    if st.button("ğŸš€ SÄkt AnalÄ«zi", type="primary"):
        with st.spinner("ğŸ¤– AI aÄ£enti analizÄ“ datus..."):
            # Run analysis
            try:
                if ML_FEATURES_AVAILABLE:
                    # Use real AI coordinator
                    from healthdq.agents.coordinator import CoordinatorAgent
                    from healthdq.config import get_config

                    config = get_config()
                    coordinator = CoordinatorAgent(config)

                    # Run async analysis
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    results = loop.run_until_complete(
                        coordinator.analyze(st.session_state.data, dimensions=dimensions)
                    )
                    loop.close()
                else:
                    # Use simulated analysis (demo mode)
                    results = _simulate_analysis(st.session_state.data, dimensions)

                st.session_state.quality_results = results
                st.session_state.workflow_stage = "review"
                st.rerun()

            except Exception as e:
                st.error(f"âŒ KÄ¼Å«da analÄ«zÄ“: {str(e)}")
                st.exception(e)


def show_review_stage():
    """Stage 3: Review results BEFORE changes."""
    st.header("3ï¸âƒ£ RezultÄtu PÄrskatÄ«Å¡ana")

    if st.session_state.quality_results is None:
        st.warning("âš ï¸ Nav analÄ«zes rezultÄtu.")
        return

    results = st.session_state.quality_results

    # Overall score
    st.subheader("ğŸ“Š KopÄ“jais KvalitÄtes VÄ“rtÄ“jums")

    overall_score = results.get("overall_score", 0.0)

    col1, col2, col3 = st.columns([2, 1, 1])

    with col1:
        # Score gauge
        score_pct = overall_score * 100
        score_color = "ğŸŸ¢" if score_pct >= 80 else "ğŸŸ¡" if score_pct >= 60 else "ğŸ”´"

        st.metric(
            "KvalitÄtes RezultÄts",
            f"{score_pct:.1f}%",
            help="KopÄ“jais datu kvalitÄtes vÄ“rtÄ“jums"
        )

        st.progress(overall_score)

    with col2:
        total_issues = results.get("metadata", {}).get("total_issues", 0)
        st.metric("KonstatÄ“tas ProblÄ“mas", total_issues)

    with col3:
        confidence = results.get("metadata", {}).get("confidence", 0.0)
        st.metric("AI PÄrliecÄ«ba", f"{confidence * 100:.0f}%")

    st.markdown("---")

    # Dimension scores
    st.subheader("ğŸ“ˆ KvalitÄtes Dimensijas")

    dimension_results = results.get("dimension_results", {})

    cols = st.columns(len(dimension_results))

    for i, (dimension, dim_results) in enumerate(dimension_results.items()):
        with cols[i]:
            score = dim_results.get("score", 0.0)
            issues_count = len(dim_results.get("issues", []))

            st.metric(
                dimension.title(),
                f"{score * 100:.1f}%",
                f"{issues_count} problÄ“mas"
            )

            st.progress(score)

    st.markdown("---")

    # Issues by dimension
    st.subheader("ğŸ” KonstatÄ“tÄs ProblÄ“mas")

    for dimension, dim_results in dimension_results.items():
        issues = dim_results.get("issues", [])

        if issues:
            with st.expander(f"**{dimension.title()}** ({len(issues)} problÄ“mas)"):
                for issue in issues:
                    severity = issue.get("severity", "medium")
                    severity_emoji = {
                        "critical": "ğŸ”´",
                        "high": "ğŸŸ ",
                        "medium": "ğŸŸ¡",
                        "low": "âšª"
                    }.get(severity, "âšª")

                    st.markdown(f"{severity_emoji} **{issue.get('type')}** - {issue.get('description')}")
                    if "column" in issue:
                        st.markdown(f"   ğŸ“ Kolonna: `{issue['column']}`")

    st.markdown("---")

    # Proposed changes
    st.subheader("ğŸ’¡ Ieteiktie Uzlabojumi")

    improvement_plan = results.get("improvement_plan", {})
    actions = improvement_plan.get("actions", [])

    if actions:
        st.info(f"â„¹ï¸ SistÄ“ma iesaka **{len(actions)}** izmaiÅ†as datu kvalitÄtes uzlaboÅ¡anai.")

        # Show actions as table
        actions_df = pd.DataFrame([
            {
                "Nr.": i + 1,
                "DarbÄ«ba": action.get("recommended_action", "N/A"),
                "Kolonna": action.get("column", "N/A"),
                "SvarÄ«gums": action.get("severity", "medium"),
            }
            for i, action in enumerate(actions)
        ])

        st.dataframe(actions_df, use_container_width=True, hide_index=True)

        # Next button
        col1, col2 = st.columns(2)

        with col1:
            if st.button("â—€ï¸ AtpakaÄ¼", use_container_width=True):
                st.session_state.workflow_stage = "assessment"
                st.rerun()

        with col2:
            if st.button("âœ… PÄrskatÄ«t un ApstiprinÄt", type="primary", use_container_width=True):
                # Create review session
                from healthdq.hitl.review import DataReview

                reviewer = DataReview()
                review_session = reviewer.create_review_session(
                    st.session_state.data,
                    results,
                    improvement_plan
                )

                st.session_state.review_session = review_session
                st.session_state.workflow_stage = "approval"
                st.rerun()
    else:
        st.success("âœ… Nav konstatÄ“tas problÄ“mas! JÅ«su dati ir augstas kvalitÄtes.")


def show_approval_stage():
    """Stage 4: Human approval."""
    st.header("4ï¸âƒ£ IzmaiÅ†u ApstiprinÄÅ¡ana")

    if st.session_state.review_session is None:
        st.warning("âš ï¸ Nav review sesijas.")
        return

    review = st.session_state.review_session
    proposed_changes = review["proposed_changes"]

    st.markdown("""
    **LÅ«dzu, pÄrskatiet un apstipriniet vai noraidiet katru ieteikto izmaiÅ†u.**

    JÅ«su feedback palÄ«dz sistÄ“mai mÄcÄ«ties un uzlaboties!
    """)

    # Create approval manager
    from healthdq.hitl.approval import ApprovalManager

    if "approval_manager" not in st.session_state:
        st.session_state.approval_manager = ApprovalManager()
        st.session_state.approval_request = st.session_state.approval_manager.create_approval_request(
            review["session_id"],
            proposed_changes
        )

    approval_manager = st.session_state.approval_manager
    approval_request = st.session_state.approval_request

    # Show each change for approval
    for i, change in enumerate(proposed_changes):
        with st.container():
            st.markdown(f"### IzmaiÅ†a #{i + 1}")

            col1, col2 = st.columns([3, 1])

            with col1:
                st.markdown(f"**DarbÄ«ba:** {change['action_type']}")
                st.markdown(f"**MÄ“rÄ·is:** {change['target']}")
                st.markdown(f"**Apraksts:** {change['description']}")
                st.markdown(f"**SvarÄ«gums:** {change['severity']}")
                st.markdown(f"**Ietekme:** {change['estimated_impact']}")

            with col2:
                approval_status = approval_request["change_approvals"][i]["approved"]

                if approval_status is None:
                    if st.button(f"âœ… ApstiprinÄt", key=f"approve_{i}"):
                        approval_manager.approve_change(approval_request["approval_id"], i)
                        st.rerun()

                    if st.button(f"âŒ NoraidÄ«t", key=f"reject_{i}"):
                        approval_manager.reject_change(
                            approval_request["approval_id"],
                            i,
                            "NoraidÄ«ts lietotÄja"
                        )
                        st.rerun()
                elif approval_status:
                    st.success("âœ… ApstiprinÄts")
                else:
                    st.error("âŒ NoraidÄ«ts")

            st.markdown("---")

    # Bulk actions
    st.subheader("âš¡ Masveida DarbÄ«bas")

    col1, col2 = st.columns(2)

    with col1:
        if st.button("âœ… ApstiprinÄt Visas", use_container_width=True):
            approval_manager.bulk_approve(
                approval_request["approval_id"],
                list(range(len(proposed_changes)))
            )
            st.rerun()

    with col2:
        if st.button("âŒ NoraidÄ«t Visas", use_container_width=True):
            approval_manager.bulk_reject(
                approval_request["approval_id"],
                list(range(len(proposed_changes))),
                "Masveida noraidÄ«Å¡ana"
            )
            st.rerun()

    # Finalize
    st.markdown("---")

    if st.button("ğŸš€ Pabeigt un PiemÄ“rot IzmaiÅ†as", type="primary", use_container_width=True):
        # Finalize approval
        final_decision = approval_manager.finalize_approval(
            approval_request["approval_id"],
            reviewer_info={"user": "streamlit_user"},
            decision_rationale="Reviewed in Streamlit UI"
        )

        st.session_state.final_decision = final_decision
        st.session_state.workflow_stage = "transformation"
        st.rerun()


def show_transformation_stage():
    """Stage 5: Apply approved transformations."""
    st.header("5ï¸âƒ£ Datu TransformÄcija")

    if st.session_state.final_decision is None:
        st.warning("âš ï¸ Nav apstiprinÄtu izmaiÅ†u.")
        return

    final_decision = st.session_state.final_decision
    approved_changes = final_decision["approved_changes"]

    st.info(f"â„¹ï¸ PiemÄ“ro {len(approved_changes)} apstiprinÄtÄs izmaiÅ†as...")

    with st.spinner("ğŸ”„ TransformÄ“ datus..."):
        try:
            from healthdq.rules.transform import DataTransformer

            transformer = DataTransformer()

            # Apply transformations
            improved_data = st.session_state.data.copy()

            for change in approved_changes:
                action_type = change.get("action_type")
                target = change.get("target")

                if action_type == "impute_missing_values":
                    improved_data = transformer.impute_missing(improved_data, column=target)
                elif action_type == "handle_outliers":
                    improved_data = transformer.handle_outliers(improved_data, column=target)
                elif action_type == "standardize_data_types":
                    improved_data = transformer.standardize_types(improved_data, column=target)
                elif action_type == "normalize_column_names":
                    from healthdq.utils.helpers import normalize_column_names
                    improved_data = normalize_column_names(improved_data)

            st.session_state.improved_data = improved_data
            st.success("âœ… TransformÄcija pabeigta!")

            st.session_state.workflow_stage = "results"
            st.rerun()

        except Exception as e:
            st.error(f"âŒ KÄ¼Å«da transformÄcijÄ: {str(e)}")


def show_results_stage():
    """Stage 6: Show results and comparison."""
    st.header("6ï¸âƒ£ RezultÄti")

    if st.session_state.improved_data is None:
        st.warning("âš ï¸ Nav uzlabotu datu.")
        return

    original_data = st.session_state.data
    improved_data = st.session_state.improved_data

    st.success("âœ… Datu kvalitÄte uzlabota!")

    # Comparison
    st.subheader("ğŸ“Š SalÄ«dzinÄjums: Pirms â†”ï¸ PÄ“c")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("### ğŸ“‹ Pirms")
        st.metric("Rindas", original_data.shape[0])
        st.metric("Kolonnas", original_data.shape[1])
        missing_before = original_data.isna().sum().sum()
        st.metric("TrÅ«kstoÅ¡as vÄ“rtÄ«bas", missing_before)

    with col2:
        st.markdown("### âœ¨ PÄ“c")
        st.metric("Rindas", improved_data.shape[0])
        st.metric("Kolonnas", improved_data.shape[1])
        missing_after = improved_data.isna().sum().sum()
        filled = missing_before - missing_after
        st.metric("TrÅ«kstoÅ¡as vÄ“rtÄ«bas", missing_after, f"-{filled}")

    # Data preview
    st.subheader("ğŸ‘€ Uzlaboto Datu PriekÅ¡skatÄ«jums")
    st.dataframe(improved_data.head(10), use_container_width=True)

    # Download
    st.subheader("ğŸ’¾ LejupielÄde")

    @st.cache_data
    def convert_df_to_csv(df):
        return df.to_csv(index=False).encode("utf-8")

    csv = convert_df_to_csv(improved_data)

    st.download_button(
        label="ğŸ“¥ LejupielÄdÄ“t CSV",
        data=csv,
        file_name="improved_data.csv",
        mime="text/csv",
        use_container_width=True,
    )

    # Start over
    if st.button("ğŸ”„ SÄkt No Jauna", use_container_width=True):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()


if __name__ == "__main__":
    main()
